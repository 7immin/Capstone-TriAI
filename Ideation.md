## 대주제: [멀티모달 엣지 AI] 각각 다른 모달리티 데이터를 갖는 클라이언트들간의 Model 차원에서의 Translation을 통한 연합 학습(Federated Learning) 연구

모달리티 간 변환을 넘어선 특정 모달리티 - Universal Modality-Independent Space 학습을 통한 모델의 확장성 확보

### 소주제: 지진 동향 분석을 위해 엣지 환경에서 연합 학습을 활용하고, 멀티모달 데이터를 Universal Modality-Indepdent Space로 통합 처리하는 AI 시스템 개발 연구

- Key word 3개: UMIS, 연합학습, 지진 동향 분석
- 누구를 위해: 지진 대응 기관(기상청, 지질조사기관, 재난안전본부 등)과 지역 주민, 나아가 재난 관리 정책 결정자들을 위해
- 누구의 어떤 문제해결 위해: 기존에는 지진 데이터가 **모달리티별(지진파, 위성 이미지, 피해 보고서 등)로 분산**되어 있어, 이를 통합적으로 분석하기 어렵고 실시간 대응이 지연됨. 따라서 **멀티모달 데이터를 통합 분석**하여, 지진의 발생 동향과 피해 규모를 더 정확하게 예측·분석할 필요가 있음
- 어떤 기술을 사용해서: 연합학습, Modality Translation, Modality Dropout, 멀티모달 엣지 AI, Universal Modality-Independent Space 학습, **Edge Computing**
- 무얼 만드려고 하는가: 지진 데이터를 **보편적 모달리티 독립 공간**에 매핑하여 통합 분석하는 **지진 동향 분석 AI 모델,** 이를 활용해 **지진 발생 예측 및 피해 추정 시스템**을 고도화 → 실시간 의사결정 지원 플랫폼

### 관련 개념 정리

- **멀티모달 엣지 AI**
    - 여러 종류의 데이터(= 모달리티, 예: 이미지, 음성, 센서값)를 다루는 AI를 서버가 아니라 **엣지 기기(스마트폰, 로봇, IoT 등)** 에서 학습/활용하는 것
- **Model 차원에서의 Translation**
    - 데이터 자체를 변환하는 게 아니라, **모델 내부에서 표현(임베딩)을 변환**해서 다른 모달리티끼리 서로 이해할 수 있게 만드는 것
- **연합 학습(Federated Learning)**
    - 데이터를 직접 주고받지 않고, 각 기기에서 학습한 **모델 파라미터(지식)** 만 모아서 공동 학습하는 방식
- **모달리티 간 변환을 넘어선 특정 모달리티 – Universal Modality-Independent Space**
    - 단순히 "이미지를 소리로 바꿔준다" 이런 게 아니라(=데이터 자체의 변환이 아니라), 아예 **어떤 모달리티(=데이터)든 공통으로 표현할 수 있는 중립적인 공간(Universal Space)** 을 만들어서 데이터를 모달리티와 상관없이 학습할 수 있게 함
